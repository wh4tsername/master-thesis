\subsection{Компоненты инструмента}

Теперь обсудим реализацию среды исполнения – рассмотрим каждый логический компонент отдельно.

\subsubsection{Сеть}

Логическая часть model checker-а – сеть – реализует абстракцию связи между серверами. По таким связям проходят сообщения в виде последовательности байт.

Как уже было сказано выше сеть – это глобальный буфер сообщений. Требования к такому буферу состоят в достаточно быстрой доставке произвольного сообщения, то есть извлечению и удалению. 

\subsubsection{Checker}

Далее опишем тот функционал, который ожидался от checker-а и был реализован.

Checker позволяет перебрать все последовательности доставки сообщений в системе, реализуя описанный выше алгоритм перебора.

Во многих тестируемых алгоритмах естественным образом возникают бесконечные ветви в графе конфигураций, что серьезно ограничивает возможность разумного перебора состояний. Для решения этой проблемы была добавлена возможность ограничения глубины пути. В таком сложном случае нужно находить баланс между глубиной пути (а значит временем исполнения) и разумностью количества посещенных состояний.

Нам важна возможность проверки исполнения на детерминизм. Возьмем для проверки некоторую ветвь исполнения.

Основная идея проверки на детерминизм – проверка на то, что состояние системы одинаково после произвольного количества запусков. Состояние системы, как уже было замечено, тяжело представимо в явном виде. Для того, чтобы однозначно понять совпадение состояний, будем поддерживать список активных аллокаций и считать некоторый хэш, комбинируя адреса аллокаций. Делаем три замера: до запуска системы, после первого запуска и после второго. Если дайджесты совпадают, то исполнение гарантируемо детерминировано.

После проверки детерминизма у нас появляется простое неявное представление пути в графе конфигураций – последовательность индексов сообщений для доставки. В таком случае в checker логично добавить возможность исполнения конкретной последовательности доставок с включенным логированием.

\subsubsection{Сервер}

Сервер является реализацией интерфейса актора и объединяет в себе несколько важных компонентов: планировщик, память, транспортный уровень сети, базу данных.

Сервер инициализирует актора через запуск всех запланированных в начальный момент времени задач.

На очередной итерации перебора после доставки сообщения узлу, актор-сервер перенаправляет вызов HandleMessage в реализацию транспортного уровня, которая порождает какое-то количество задач в очереди планировщика. Дальше происходит шаг сервера, состоящий в опустошении очереди планировщика, или на уровне акторов – в переходе в новое состояние в автомате.

\paragraph{Планировщик}\mbox{}

Как уже обсуждалось выше, аналогично задаче построения детерминированной симуляции, нам требуется реализация псевдоконкурентности. Для целей детерминированного исполнения конкурентного кода используется\\ Manual Executor. Такой планировщик представляет собой очередь с задачами, которые планируются в нее из различных мест – fiber-ы, RPC рантайм, коллбэки с кодом пользователя. Далее есть возможность выполнения всех порожденных задач и опустошения очереди, что переводит недетерминированный конкурентный код в state machine.

\paragraph{Память}\mbox{}

Перед тем как рассмотреть реализацию памяти узла, нужно затронуть тему многоразового запуска системы и остановки её в произвольный момент.

Запуск и остановка системы – важная часть checker-а. Перебор строится на возможности множественного перезапуска и остановки системы без утечек памяти.

При завершении исследования ветви в графе конфигураций нам нужно сбросить состояния всех узлов, для этого мы изолируем состояние каждого узла в отдельной куче. Это решение состоит в том, чтобы для узла иметь собственный аллокатор, арену которого в нужный момент можно переиспользовать, затирая все объекты, оставшиеся с прошлых итераций. Более того, различные узлы, для упрощения, могут иметь общий аллокатор, но, в силу разделения их на уровне дизайна, не вторгаться в чужую память.

Итак, память узла – отдельный аллокатор. В реализации используется версия аллокатора с поддержанием списка свободных блоков и простым кэшированием.

В этом месте становится ясно, почему для реализации был выбран язык С++. Помимо необходимости эффективности перебора, нам требуется иметь возможность управлять аллокатором. По этой причине языки со сборкой мусора не подойдут.

\paragraph{Другие компоненты}\mbox{}

Теперь можно поговорить про менее важные компоненты.

Была реализована абстракция транспортного уровня ITransport, благодаря которой возможно легко взаимодействовать узлам по RPC на уровне checker-а. Предоставляются сокеты, возможность подключения к серверу, возможность слушать с некоторым коллбэком на порте. Поддержку disconnect-ов в checker-е можно опустить, так как disconnect одной из сторон – отсутствие доставки некоторого сообщения, что реализуется на уровне алгоритма checker-а.

Поддержание DNS нужно для корректной трансляции адресов транспортного уровня в идентификаторы акторов и наоборот. DNS позволяет нам поддерживать подключение к другим серверам.

Код внутри узла для персистентного хранения данных опирается на интерфейс IDatabase. В model checker-е он реализуется через упорядоченное отображение ключа в значение. Благодаря тому, что мы не моделируем дисковые сбои, отображение – это in-memory map.

Для реализации среды исполнения требуется определить менеджер fiber-ов. Это класс отвечающий за выдачу стеков при создании fiber-а.

\subsubsection{Мир}

Сущности сети и серверов, как акторов, находятся в обобщающем классе, который называется World. Перед запуском перебора исполнений в checker-е в этот класс складываются entry point-ы клиентов и серверов. Мир также содержит в себе бэкенд часть логирования, генератор случайных чисел, поддерживает именованные пулы серверов. Этот класс также хранит предикат для проверки инвариантов. Важной функцией мира является старт и остановка всей системы: серверов, сети, глобальных генераторов (GUID, random).

Генератор GUID является просто монотонным счетчиком.

Сервис генерации случайного числа реализуется стандартным образом через вихрь Мерсенна с возможностью сброса состояния генератора.

Сервис Discovery реализует функцию поиска по названию пула списка адресов серверов, входящих в него, через поддержание такого отображения.

\subsubsection{Логирование поведения}

В фреймворке логирование опирается на интерфейс среды ILogBackend. В инструменте реализовано логирование по уровням для управления детализацией отчета. Минимальный уровень, который будет выводиться в файл, можно задать с помощью переменной окружения. 

Далее происходит захват контекста model checker-а: получение компонента, из которого выполняет логирование, проверка соответствия уровню детализации. На этом этапе происходит формирование структуры Event, в которой собраны номер шага, уровень логирования, краткое описание актора, компонент, в котором вызвано логирование, и само сообщение.
